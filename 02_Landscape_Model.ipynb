{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b68488",
   "metadata": {},
   "source": [
    "# The Revised Landscape Model\n",
    "\n",
    "Here we reproduce the revision of the Landscape model of reading comprehension presented by Yeari and van den Broek (2016). The model integrates the dynamic landscape model of reading comprehension originally characterized by van den Broek (1996) with a latent semantic analysis (LSA) representation of semantic knowledge. This revised landscape model (LS-R model) computes fluctuations in the activation of text units and the interconnections established between them throughout reading. Our implemention of the landscape model is, however, agnostic about the basis of representations of semantic knowledge.\n",
    "\n",
    "> Yeari, M., & van den Broek, P. (2016). A computational modeling of semantic knowledge in reading comprehension: Integrating the landscape model with latent semantic analysis. Behavior research methods, 48(3), 880-896."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d986a8c7",
   "metadata": {},
   "source": [
    "## The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8162876",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class LandscapeRevised:\n",
    "    \"\"\"\n",
    "    The landscape model of reading as revised by Yeari and van den Broek (1996).\n",
    "    To encode a text into the model, it is initially segmented into text units \n",
    "    (e.g., words or propositions) and reading cycles (e.g., clauses or  \n",
    "    sentences) depending on researcher preference. Similarly, semantic \n",
    "    connections between all text units are also computed before model \n",
    "    initialization. In the original specification of LS-R, semantic \n",
    "    connections are computed using LSA, but we leave configuration of initial \n",
    "    semantic connections separate from the model. This revised landscape model \n",
    "    computes fluctuations in the _activation_ of text units and in the \n",
    "    _interconnections_ established between them throughout reading.\n",
    "    \n",
    "    Basic Parameters:  \n",
    "    - connections: array, initial connection strengths between text units  \n",
    "    - max_activity: maximum activation that units are allowed to have  \n",
    "    - min_activity: minimum activation that units are allowed to have  \n",
    "    - decay_rate: decay rate of unit activation from one cycle to next  \n",
    "    - memory_capacity: total activation possible in any given cycle  \n",
    "    - learning_rate: rate of connection weight changes across cycles  \n",
    "    - semantic_strength: relative contribution of initial semantic  \n",
    "        connections to computation of overall connection strengths  \n",
    "    \n",
    "    Retrieval Parameters (imported from CMR, only relevant for free recall):  \n",
    "    - stop_probability_scale\n",
    "    - stop_probability_growth\n",
    "    - choice_sensitivity\n",
    "    \n",
    "    Attributes:\n",
    "    - activations: vector, current activation of each relevant text unit\n",
    "    - connections: array, current connection strengths between text units\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, connections, stop_probability_scale=1.0, \n",
    "                 stop_probability_growth=1.0, choice_sensitivity=1.0, \n",
    "                 max_activity=1.0, min_activity=0.0, decay_rate=0.1, \n",
    "                 memory_capacity=5.0, learning_rate=0.9, \n",
    "                 semantic_strength=1.0):\n",
    "        \n",
    "        # store initial parameters\n",
    "        self.unit_count = len(connections)\n",
    "        self.stop_probability_scale = stop_probability_scale\n",
    "        self.stop_probability_growth = stop_probability_growth\n",
    "        self.choice_sensitivity = choice_sensitivity\n",
    "        self.max_activity = max_activity\n",
    "        self.min_activity = min_activity\n",
    "        self.decay_rate = decay_rate\n",
    "        self.memory_capacity = memory_capacity\n",
    "        self.learning_rate = learning_rate\n",
    "        self.semantic_strength = semantic_strength\n",
    "        \n",
    "        # model architecture is set of activations and connections \n",
    "        # across units diagonal of connections is 0 since we disallow \n",
    "        # self-connections\n",
    "        self.connections = connections * self.semantic_strength\n",
    "        self.activations = np.zeros(self.unit_count) + self.min_activity\n",
    "        \n",
    "        # other variables to help track encoding/retrieval across trials\n",
    "        self.recall_total = 0\n",
    "        self.cycle_index = 0\n",
    "        self.retrieving = False\n",
    "        self.recall = np.zeros(self.unit_count)\n",
    "        self.preretrieval_activations = self.activations\n",
    "        \n",
    "    def experience(self, cycles):\n",
    "        \"\"\"\n",
    "        Updates activations and connections based on content of current \n",
    "        reading cycle.\n",
    "        \n",
    "        Activations are updated as a function of three simulated mechanisms:  \n",
    "        1. attention: units of the current cycle are activated to the \n",
    "            highest value  \n",
    "        2. working memory: units from prior cycles carry residual activation \n",
    "            (following a decay rule)  \n",
    "        3. long-term memory: units from prior cycles are reactivated via\n",
    "            connections with text units that are active in the current cycle. \n",
    "            \n",
    "        Episodic connections are added to and augment baseline connection \n",
    "        strengths throughout the dynamic flow from one reading cycle to the \n",
    "        next. They are formed between text units that are coactivated (due to \n",
    "        any activation mechanism) in the same reading cycle. The strength of \n",
    "        episodic connections is a function of the activation levels of the \n",
    "        interconnected text units, and it accumulates with each concurrent \n",
    "        activation (following a logarithmic learning rule). \n",
    "        \n",
    "        Argument:  \n",
    "        - cycles: vector of counts of units processed in each cycle\n",
    "        \"\"\"\n",
    "        \n",
    "        for cycle in cycles:\n",
    "            self.update_activations(cycle)\n",
    "            self.update_connections(self.activations)\n",
    "        self.cycle_index += len(cycles)\n",
    "            \n",
    "        def update_activations(self, cycle):\n",
    "            \"\"\"\n",
    "            Updates unit activations based on current reading cycle.\n",
    "            \n",
    "            1. Previous cycle activations decay by a parametrized amount \n",
    "            toward a parametrized minimum value and spread to connected units.\n",
    "            3. Regardless of outcome, the activations of units in the current \n",
    "                cycle are set to the maximum allowed value.  \n",
    "            4. Finally activations are reduced proportionately based on \n",
    "                memory_capacity.\n",
    "            \"\"\"\n",
    "            \n",
    "            # Previous cycle activations decay by a parametrized amount toward\n",
    "            # some parametrized minimum value and spread to connected units.\n",
    "            sigma = np.tanh(3 * (self.connections - 1)) + 1\n",
    "            self.activations = self.decay_rate * (sigma * self.activations)\n",
    "            \n",
    "            # activations of current cycle units set to maximum allowed value\n",
    "            self.activations[cycle] = self.max_activity\n",
    "            \n",
    "            # activations of all units get set to at least minimum activation\n",
    "            self.activations = np.maximum(self.activations, self.min_activity)\n",
    "            \n",
    "            #  if sum of activations exceeds capacity limit, \n",
    "            # activations are reduced proportionally to attain the limit\n",
    "            total_activation = np.sum(self.activations)\n",
    "            if total_activation > self.memory_capacity:\n",
    "                self.activations *=  self.memory_capacity / total_activation\n",
    "                \n",
    "        def update_connections(self, activations):\n",
    "            \"\"\"\n",
    "            Updates model connection weights based on current unit activations.\n",
    "            \n",
    "            Connection strength is accumulated from one cycle to the next as a \n",
    "            function of the activation levels of the connected units. The \n",
    "            learning_rate parameter controls the rate of change, with a high value \n",
    "            representing a higher rate of learning from previous textual \n",
    "            information. Because learning_rate or activation values cannot be \n",
    "            smaller than 0, the connection strength necessarily is above 0, and \n",
    "            changes are incremental.\n",
    "            \"\"\"\n",
    "            self.connections += self.learning_rate * np.outer(\n",
    "                activations, activations)\n",
    "            \n",
    "        def outcome_probabilities(self):\n",
    "            \"\"\"\n",
    "            Current unit recall probabilities given model state.\n",
    "            \"\"\"\n",
    "            \n",
    "            activation = np.power(self.activations, self.choice_sensitivity)\n",
    "            probabilities = np.zeros((self.unit_count + 1))\n",
    "            probabilities[0] = min(self.stop_probability_scale * np.exp(\n",
    "                self.recall_total * self.stop_probability_growth), 1.0  - (\n",
    "                (self.unit_count - self.recall_total) * 10e-7))\n",
    "            \n",
    "            for already_recalled_item in self.recall[:self.recall_total]:\n",
    "                activation[int(already_recalled_item)] = 0\n",
    "            probabilities[1:] = (\n",
    "                1-probabilities[0]) * activation / np.sum(activation)\n",
    "\n",
    "            return probabilities\n",
    "        \n",
    "        def free_recall(self, steps=None):\n",
    "            \n",
    "            # ensure retrieval information is reset\n",
    "            if not self.retrieving:\n",
    "                self.recall = np.zeros(self.unit_count)\n",
    "                self.recall_total = 0\n",
    "                self.preretrieval_activations = self.activations\n",
    "                self.retrieving = True\n",
    "\n",
    "            # we retrieve until termination if steps is left unspecified\n",
    "            if steps is None:\n",
    "                steps = self.unit_count - self.recall_total\n",
    "            steps = self.recall_total + steps\n",
    "\n",
    "            # at each recall attempt\n",
    "            while self.recall_total < steps:\n",
    "\n",
    "                # the current state of context is used as a retrieval cue to \n",
    "                # attempt recall of a studied item compute outcome probabilities \n",
    "                # and make choice based on distribution\n",
    "                outcome_probabilities = self.outcome_probabilities()\n",
    "                if np.any(outcome_probabilities[1:]):\n",
    "                    choice = np.sum(\n",
    "                        np.cumsum(outcome_probabilities) < np.random.rand())\n",
    "                else:\n",
    "                    choice = 0\n",
    "\n",
    "                # resolve and maybe store outcome\n",
    "                # we stop recall if no choice is made (0)\n",
    "                if choice == 0:\n",
    "                    self.retrieving = False\n",
    "                    self.activations = self.preretrieval_activations\n",
    "                    break\n",
    "                self.recall[self.recall_total] = choice - 1\n",
    "                self.recall_total += 1\n",
    "                self.update_activations([choice - 1])\n",
    "            return self.recall[:self.recall_total]\n",
    "        \n",
    "        def force_recall(self, choice=None):\n",
    "\n",
    "            # ensure retrieval information is reset\n",
    "            if not self.retrieving:\n",
    "                self.recall = np.zeros(self.unit_count)\n",
    "                self.recall_total = 0\n",
    "                self.preretrieval_activations = self.activations\n",
    "                self.retrieving = True\n",
    "\n",
    "            # resolve and maybe store outcome\n",
    "            # we stop recall if no choice is made (0)\n",
    "            if choice is None:\n",
    "                pass\n",
    "            elif choice > 0:\n",
    "                self.recall[self.recall_total] = choice - 1\n",
    "                self.recall_total += 1\n",
    "                self.update_activations([choice - 1])\n",
    "            else:\n",
    "                self.retrieving = False\n",
    "                self.activations = self.preretrieval_activations\n",
    "            return self.recall[:self.recall_total]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12d5a25",
   "metadata": {},
   "source": [
    "## Simulation Configuration\n",
    "Let's demonstrate how to efficiently simulate the Landscape Model using the stimuli from our SBS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a00f35",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
