I think I've somewhat concretized how we might blend the CMR model of general free recall with the Landscape model of narrative comprehension/memory, and started developing a corresponding "science" narrative around that integration.

We've been referencing \citet{morton2016predictive} already to help plan our model fitting, but it also proposes and analyzes some variants of CMR that try to account for the influence of semantic knowledge on the course of free recall. At the center of all the CMR variants with semantic cueing is a matrix $M^{sem}$ that gives the semantic similarity between each item according to some distributional semantics model. Combining information from that matrix with a contextual cue when deciding what to recall next made the model work better, even if you apply a cost for the added parameters necessary to configure that.

The landscape model of reading comprehension is just an account of how semantic knowledge in of the context of a narrative evolves over the course of comprehension. It starts out just like CMR's $M^{sem}$ does: as a record of the semantic similarities between each relevant idea unit. But while the matrix is static in CMR, it evolves in the landscape model based on idea unit coactivation (and retrieval/reactivation of idea units based on ongoing connectivity) over the course of reading. Its final output is thus an updated $M^{sem}$ reflecting both prior semantic knowledge and the unique structure of the studied narrative. The explanatory effectiveness of this account of offline recall hasn't been as thoroughly analyzed as CMR's, but the correlation between connection strengths simulated this way and recall rates for corresponding idea units has been reported as .70, with p < .01. And all without any model fitting, just default parameters.

Integrating the landscape model with CMR thus at minimum only requires using the landscape model's simulated semantic connectivity matrix in place of the purely DSM-based $M^{sem}$ matrix considered so far in the \citet{morton2016predictive} paper.

There might be ways to blend the models even more deeply, sure. For example, the landscape model tracks idea unit coactivation with a recency-weighted representation vaguely similar to CMR's context, and it might be redundant to use both. And alternatively, particularly given these analogies, maybe we'll find that associations tracked between items with a semantic-cueing variant CMR already captures most of what makes the landscape model work.

To find out, aside from performing fit-based comparison between these different models, we can check whether semantic-CMR predicts the centrality effect in narrative memory reported across the literature, including in recent work by our colleagues: idea units more "central" to a text are recalled more easily than less central units. Much of the landscape model's success is likely attributable to the fact that its simulated connectivity patterns track the continuum of centrality across idea units in narratives even better than it does recall rates. For example, a recent correlation test of simulated connection weights against a dataset of centrality judgements made by separate research participations found an r = .79, with p < .01.

I suspect we'll find that even the semantic variants of CMR are not so good at tracking idea unit centrality. They'll do fine tracking temporal organization of course, and even will do a good job of accounting for the influence of pre-experimental semantic associations. But the Landscape model's design suggests that the secret sauce for a variant of CMR that can account for the way narrative structure shapes the course of recall is just a version of $M^{sem}$ that's more sensitive to that narrative structure.

Casting our work as I just said makes it sound obvious, but it also makes it nice and incremental. We're just taking the next logical step from \citet{morton2016predictive} and \citet{yeari2016computational}, we already have a good idea of what outcome we'll get, and yet it'll be a big deal thing no one's done before anyway.