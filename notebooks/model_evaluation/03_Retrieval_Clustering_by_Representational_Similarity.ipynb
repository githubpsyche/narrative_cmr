{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6963e29f",
   "metadata": {},
   "source": [
    "# Clustering by Representational Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a004e472",
   "metadata": {},
   "source": [
    "Previous work has applied a distance rank analysis to summarize with a single scalar value the tendency to group together nearby items using various distance metrics, including serial order and semantic similarity. This analysis is also probably applicable to measure the extent how recall is clustered according to latent representational states inferred with our models. For example, the distance_rank analysis can be applied to data using semantic similarities from GloVe, but also to semantic connections simulated with the Landscape model.\n",
    "\n",
    "To really underline how dynamics within the Landscape model progressively _evolve_ a representation of semantic associations between items, we can simulate the study phase of each trial using the model's default parameters and track this distance_rank statistic at each increment. A horizontal line records the initial value based on pre-existing semantic associations, also the default matrix used for SemanticCMR and associated analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d8bd99",
   "metadata": {},
   "source": [
    "## Load Relevant Dependencies and Data\n",
    "For flexibility, we'll retrieve our own similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3fa977",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Landscape_Model import LandscapeRevised\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from psifr import fr\n",
    "import spacy\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# load recall data frame\n",
    "data = pd.read_csv('data/psifr_sbs.csv')\n",
    "events = fr.merge_free_recall(\n",
    "    data, list_keys=['item_index', 'cycle', 'story_index', \n",
    "                     'story_name', 'time_test'])\n",
    "\n",
    "# paraphrase-MiniLM-L12-v2\n",
    "# average_word_embeddings_glove.6B.300d\n",
    "# average_word_embeddings_glove.840B.300d\n",
    "# stsb-distilbert-base\n",
    "model = SentenceTransformer('stsb-distilbert-base')\n",
    "units = events.pivot_table(index=['story_name', 'input'], values='item', aggfunc='first').reset_index()\n",
    "connections = {}\n",
    "remove_stopwords = False\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "for story_name in ['Fisherman', 'Supermarket', 'Flight', 'Cat', 'Fog', 'Beach']:\n",
    "    \n",
    "    sentences = units.loc[units.story_name==story_name].item.values.tolist()\n",
    "    \n",
    "    clean_sentences = []\n",
    "    for i in range(len(sentences)):\n",
    "        if remove_stopwords:\n",
    "            text_token = nlp(sentences[i])\n",
    "            clean_sentences.append(' '.join([word.text for word in text_token if not word.is_stop]))\n",
    "        else:\n",
    "            clean_sentences.append(sentences[i])\n",
    "    \n",
    "    #Compute embeddings\n",
    "    embeddings = model.encode(clean_sentences, convert_to_tensor=True)\n",
    "\n",
    "    #Compute cosine-similarities for each sentence with each other sentence\n",
    "    cosine_scores = util.pytorch_cos_sim(embeddings, embeddings).numpy()\n",
    "    cosine_scores[np.eye(len(cosine_scores), dtype='bool')] = 1\n",
    "    connections[story_name] = cosine_scores\n",
    "\n",
    "events.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad547b",
   "metadata": {},
   "source": [
    "## Demo Representational Clustering Analysis for Initial Model State\n",
    "For each story and time_test, initialize the model with the relevant connectivity matrix, perform the lag_rank analysis over the dataset using the matrix, combine dataFrames, and plot the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9a2536",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_ranks = []\n",
    "\n",
    "# build list of distance_rank dfs across each factor i'm interested\n",
    "for time_test in pd.unique(events.time_test):\n",
    "    for story_name in pd.unique(events.story_name):\n",
    "\n",
    "        # initialize the model with the relevant connectivity matrix\n",
    "        model = LandscapeRevised(connections[story_name])\n",
    "\n",
    "        # perform the distance_rank analysis over the dataset using the matrix\n",
    "        distance_rank = fr.distance_rank(\n",
    "            events.loc[(events.story_name==story_name) & (events.time_test==time_test)], \n",
    "            'item_index', 1-model.connections).reset_index()\n",
    "\n",
    "        distance_rank['story_name'] = story_name\n",
    "        distance_rank['time_test'] = time_test\n",
    "        distance_ranks.append(distance_rank)\n",
    "        \n",
    "distance_rank = pd.concat(distance_ranks)\n",
    "distance_rank = distance_rank.loc[distance_rank.time_test != 1]\n",
    "distance_rank = distance_rank.pivot_table(index=['time_test', 'subject'], values='rank').reset_index()\n",
    "distance_rank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52591c2",
   "metadata": {},
   "source": [
    "**Note**: Some of these rank values are nan for a given subject and condition. This is because participants didn't recall anything during these particular trials. This doesn't seem to affect downstream analyses. We'll demonstrate as much with our successive analysis: a dotplot of semantic organization scores factored by time_test and subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6b8dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "sns.lmplot(data=distance_rank, \n",
    "    x=\"time_test\", y=\"rank\", palette=\"deep\");\n",
    "plt.xticks([2, 3], ['Immediate', 'Delayed'])\n",
    "plt.xlim([1.5, 3.5])\n",
    "plt.ylim([.5, .65])\n",
    "plt.xlabel('Time of Test')\n",
    "plt.ylabel('Baseline Representational Clustering');\n",
    "plt.savefig('results/Lmplot_Time_Test_by_Distance_Rank_Glove840B_by_Subject.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6089bc8c",
   "metadata": {},
   "source": [
    "## Simulation Configuration\n",
    "Before getting into more detailed analyses, let's demonstrate how to efficiently simulate the Landscape Model using the stimuli from our SBS dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc9255b",
   "metadata": {},
   "source": [
    "DataFrame construction should look much like the above, except with an extra factor varied over: `simulation_step`. From there, I'll apply another `pivot_table`, this time generalizing over subjects (or perhaps letting seaborn do that for me with its confidence interval support). The objective is a lineplot relating `simulation_step` with mean organization score across subjects.\n",
    "\n",
    "But what about simulation configuration? The key thing to work through is how to operate the `cycles` argument of `LandscapeRevised.experience`. The important thing is that each entry of `cycles` selects the right entries of `self.activations` to update when I assign `self.max_activity` within `LandscapeRevised.update_activations`. This probably just requires a list of indices per entry, right? Do I already have code for that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "346c486f",
   "metadata": {},
   "source": [
    "### Cycle Extraction\n",
    "Let's just directly get a list of cycles containing indices of relevant units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ea7efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiences = {}\n",
    "\n",
    "cycle_table = events.pivot_table(index=['story_name'], columns='input', values='cycle')\n",
    "\n",
    "for story_name in connections.keys():\n",
    "    v = cycle_table.loc[story_name].values\n",
    "    v = v[~np.isnan(v)]\n",
    "    \n",
    "    next_experience = []\n",
    "    current_cycle = 0\n",
    "    experiences[story_name] = []\n",
    "\n",
    "    for unit_index, cycle_index in enumerate(v):\n",
    "        if current_cycle != cycle_index:\n",
    "            experiences[story_name].append(next_experience)\n",
    "            next_experience = [unit_index]\n",
    "            current_cycle = cycle_index\n",
    "        else:\n",
    "            next_experience.append(unit_index)\n",
    "\n",
    "print(experiences['Fisherman'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54af046",
   "metadata": {},
   "source": [
    "## Extend Distance_Rank Analysis Over Each Simulation Step\n",
    "This time, we'll take the representational clustering analysis we demoed above and apply it over each simulation step, tracking changes in analysis result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_distance_ranks = []\n",
    "sim_connections = {}\n",
    "\n",
    "# build list of distance_rank dfs across each factor i'm interested\n",
    "for time_test in pd.unique(events.time_test):\n",
    "    for story_name in pd.unique(events.story_name):\n",
    "\n",
    "        # initialize model and store initial sim_distance_rank df\n",
    "        model = LandscapeRevised(connections[story_name])\n",
    "\n",
    "        # perform the distance_rank analysis over the dataset using the matrix\n",
    "        sim_distance_rank = fr.distance_rank(\n",
    "            events.loc[(events.story_name==story_name) & (events.time_test==time_test)], \n",
    "            'item_index', 1-model.connections).reset_index()\n",
    "\n",
    "        # factor-specific information\n",
    "        sim_distance_rank['story_name'] = story_name\n",
    "        sim_distance_rank['time_test'] = time_test\n",
    "        sim_distance_rank['simulation_step'] = 0\n",
    "        sim_distance_ranks.append(sim_distance_rank)\n",
    "\n",
    "        # add a further inner loop over cycles in story_name\n",
    "        for cycle_index, cycle in enumerate(experiences[story_name]):\n",
    "            model.experience([cycle])\n",
    "\n",
    "            # perform the distance_rank analysis over the dataset using the matrix\n",
    "            sim_distance_rank = fr.distance_rank(\n",
    "                events.loc[(events.story_name==story_name) & (events.time_test==time_test)], \n",
    "                'item_index', 1-model.connections).reset_index()\n",
    "\n",
    "            # factor-specific information\n",
    "            sim_distance_rank['story_name'] = story_name\n",
    "            sim_distance_rank['time_test'] = time_test\n",
    "            sim_distance_rank['simulation_step'] = int(cycle_index + 1)\n",
    "            sim_distance_ranks.append(sim_distance_rank)\n",
    "\n",
    "        sim_connections[story_name] = model.connections.copy()\n",
    "\n",
    "sim_distance_rank = pd.concat(sim_distance_ranks)\n",
    "#sim_distance_rank = sim_distance_rank.loc[sim_distance_rank.time_test != 1]\n",
    "sim_distance_rank.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342b4762",
   "metadata": {},
   "source": [
    "Let's confirm that the analysis is solid by reproducing our above plot for just a single simulation_step in our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3074843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "arbitrary_step = 10\n",
    "subset = sim_distance_rank[sim_distance_rank.simulation_step==arbitrary_step].pivot_table(index=['time_test', 'subject'], values='rank').reset_index()\n",
    "\n",
    "sns.set(style='whitegrid')\n",
    "sns.scatterplot(data=subset, \n",
    "    x=\"time_test\", y=\"rank\");\n",
    "sns.lineplot(data=subset, \n",
    "    x=\"time_test\", y=\"rank\", ci=False);\n",
    "plt.xticks([1, 2, 3], ['First Immediate', 'Second Immediate', 'Delayed'])\n",
    "plt.xlim([.5, 3.5])\n",
    "plt.xlabel('Time of Test')\n",
    "plt.ylabel('Simulated Semantic Clustering at Step {}'.format(arbitrary_step));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad73eb0",
   "metadata": {},
   "source": [
    "Next is a line plot relating simulation_step with representational clustering score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb316ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set(style='darkgrid')\n",
    "g = sns.lineplot(data=sim_distance_rank, x='simulation_step', y='rank', hue='time_test', palette='pastel')\n",
    "plt.xlabel('Simulation Step')\n",
    "plt.ylabel('Representational Clustering in Recall')\n",
    "plt.title('Clustering by Representational Similarity: Landscape Model')\n",
    "plt.legend(['First Immediate', 'Second Immediate', 'Delayed'], title='Time of Test');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755ff962",
   "metadata": {},
   "source": [
    "And again, but factored by story."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa6be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "\n",
    "g = sns.FacetGrid(sim_distance_rank.loc[sim_distance_rank.time_test==2], height=5, col='time_test')\n",
    "g.map_dataframe(sns.lineplot, 'simulation_step', 'rank', hue='story_name', palette='pastel');\n",
    "#g.set(xticks=np.arange(0, 46, 2))\n",
    "g.set_xlabels('Model Simulation Step')\n",
    "g.set_ylabels('Recall Clustering by Model Connection Weights')\n",
    "plt.title('The Landscape Model Accounts for Recall Organization\\nMuch Better Than Semantic Similarity Alone')\n",
    "plt.legend(title='Story')\n",
    "plt.savefig('results/Lineplot_LMR_Distance_Rank_by_Simulation_Step_by_Story.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f0780b",
   "metadata": {},
   "source": [
    "## Semantic Similarity Matrix Follow-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa70fbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_name in sim_connections.keys():\n",
    "    print(story_name)\n",
    "    print(np.nanmax(sim_connections[story_name]), np.nanmin(sim_connections[story_name]))\n",
    "    print(np.median(sim_connections[story_name]), np.nanmax(sim_connections[story_name])/np.median(sim_connections[story_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d1d7a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for story_name in sim_connections.keys():\n",
    "    \n",
    "    sns.heatmap(sim_connections[story_name], xticklabels=5, yticklabels=5, vmin=0, vmax=1)\n",
    "    plt.title(story_name)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893255cd",
   "metadata": {},
   "source": [
    "Some cells in these connectivity matrices contain unbelievably high weights compared to other values, with the maximum cell value ranging from 70 times to 544 times the median cell value. This could be a sign of some bug in the model simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b739f",
   "metadata": {},
   "source": [
    "## Correlation Follow-Up\n",
    "Yeari et al found that the Landscape model's simulated connection strengths were positively associated with recall proportions (r s = .70, p < .01; Fig. 1b). Can we reproduce that finding here? We'd redo `Lmplot_Probability_Recall_by_Mean_Glove840B_Cosine_Similiarity.svg` from the `Cutler_Poster_Reproduction`, but using fully simulated Landscape Model representations instead of initial similarities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b80a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_connection_strengths = {}\n",
    "for story_name in sim_connections.keys():\n",
    "    sim_connection_strengths[story_name] = np.nanmean(sim_connections[story_name], axis=1)\n",
    "\n",
    "strengths_df = events.pivot_table(\n",
    "    index=['story_name', 'time_test', 'input'], values='recall').reset_index()\n",
    "strengths_df['cosine_similarity'] = np.nan\n",
    "\n",
    "for story_name in pd.unique(events.story_name):\n",
    "    for time_test in range(1, 4):\n",
    "        for input in range(1, len(sim_connection_strengths[story_name])+1):\n",
    "            if len(strengths_df.loc[(strengths_df.story_name == story_name) & (\n",
    "                strengths_df.time_test == time_test) & (strengths_df.input == input)]) == 1:\n",
    "\n",
    "                strengths_df.loc[(strengths_df.story_name == story_name) & (\n",
    "                    strengths_df.time_test == time_test) & (\n",
    "                        strengths_df.input == input), 'cosine_similarity'] = sim_connection_strengths[story_name][input-1]\n",
    "\n",
    "strengths_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bdc8e3",
   "metadata": {},
   "source": [
    "And some corresponding correlation tests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1074e5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for time_test in pd.unique(events.time_test):\n",
    "    print('all', time_test)\n",
    "    print(stats.pearsonr(strengths_df.loc[strengths_df.time_test == time_test].recall, strengths_df.loc[strengths_df.time_test == time_test].cosine_similarity))\n",
    "\n",
    "    for story_name in pd.unique(strengths_df.story_name):\n",
    "        print(story_name, time_test)\n",
    "        print(stats.pearsonr(strengths_df.loc[(strengths_df.story_name == story_name) & (strengths_df.time_test == time_test)].recall, strengths_df.loc[(strengths_df.story_name == story_name) & (strengths_df.time_test == time_test)].cosine_similarity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9316375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for time_test in range(1, 4):\n",
    "    print('Time Test == {}'.format(time_test))\n",
    "    print(strengths_df.loc[strengths_df.time_test == time_test].corr().to_markdown())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7596ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='whitegrid')\n",
    "g = sns.FacetGrid(strengths_df.loc[strengths_df.time_test == 1], \n",
    "    col='story_name', height=5)\n",
    "g.map_dataframe(sns.lineplot, 'input', 'cosine_similarity');\n",
    "g.set(xticks=np.arange(0, 46, 2))\n",
    "plt.savefig('results/Lmplot_Probability_Recall_by_Mean_Connection_Weight.svg')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cb9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme(style='whitegrid')\n",
    "    \n",
    "sns.lmplot(data=strengths_df.loc[strengths_df.time_test > 1], \n",
    "    x=\"cosine_similarity\", y=\"recall\", palette=\"deep\", hue='time_test', legend=False);\n",
    "plt.xlabel('Mean Simulated Connection Weight')\n",
    "plt.ylabel('Unit Recall Rate');\n",
    "plt.legend(['immediate', 'delay'], title='time of test');\n",
    "plt.savefig('results/Lmplot_Probability_Recall_by_Mean_Connection_Weight.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8105282a",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.lmplot(data=strengths_df.loc[strengths_df.time_test > 1], \n",
    "    x=\"cosine_similarity\", y=\"recall\", palette=\"deep\", hue='time_test', col='story_name', col_wrap=3, legend=False);\n",
    "plt.xlabel('Mean Simulated Connection Weight')\n",
    "plt.ylabel('Unit Recall Rate');\n",
    "plt.legend(['immediate', 'delay'], title='time of test');\n",
    "plt.savefig('results/Lmplot_Probability_Recall_by_Mean_Connection_Weight_by_Story.svg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43224165",
   "metadata": {},
   "source": [
    "Totally flat! Quite concerning that I couldn't reproduce the result. Yeah, I probably do have to look into this more closely."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51531161",
   "metadata": {},
   "source": [
    "## Semantic CRP Follow-Up\n",
    "Similarly redo `FacetGrid_SemCRP_by_Time_Test` from the `Cutler_Poster_Reproduction` but using simulated model connectivities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbe59fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_crps = []\n",
    "\n",
    "# choose bins for CRP\n",
    "bin_size = .1\n",
    "np.arange(0, 1 + bin_size, bin_size)\n",
    "edges = np.arange(0, 1 + bin_size, bin_size)\n",
    "\n",
    "# build list of sem_crps across each factor i'm interested\n",
    "for time_test in pd.unique(events.time_test):\n",
    "    for story_name in pd.unique(events.story_name):\n",
    "        subset = events.loc[(events.time_test == time_test) & (\n",
    "            events.story_name == story_name)]\n",
    "        dcrp = fr.distance_crp(\n",
    "            subset, 'item_index', sim_connections[story_name], edges)\n",
    "        dcrp['story_name'] = story_name\n",
    "        if time_test == 1:\n",
    "            dcrp['time_test'] = 1\n",
    "        elif time_test == 2:\n",
    "            dcrp['time_test'] = 'immediate'\n",
    "        else:\n",
    "            dcrp['time_test'] = 'delayed'\n",
    "        sem_crps.append(dcrp)\n",
    "    \n",
    "sem_crp = pd.concat(sem_crps).reset_index()\n",
    "sem_crp = sem_crp.loc[sem_crp.time_test != 1]\n",
    "sem_crp = sem_crp.pivot_table(index=['time_test', 'subject', 'center'], values='prob').reset_index()\n",
    "sem_crp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52cbee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(data=sem_crp, col='time_test')\n",
    "g.map_dataframe(sns.lineplot, x='center', y='prob')\n",
    "g.map_dataframe(sns.scatterplot, x='center', y='prob', hue='subject', palette='pastel')\n",
    "g.set_xlabels('Similarity')\n",
    "g.set_ylabels('CRP');\n",
    "plt.savefig('results/Lineplot_Model_DistanceCRP_by_Time_Test.svg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000ae9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
