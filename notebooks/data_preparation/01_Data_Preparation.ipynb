{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557afe71",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "Most of our analyses don't work directly on the text data we preprocess above. Instead, we want something formatted more like the traditional object of free recall modeling: sequences of study events and recall events related based on item identity, serial position, and other task features. \n",
    "\n",
    "We'll follow the approach of the [Psifr library](https://psifr.readthedocs.io/en/latest/index.html) and represent most of our data in a long table format, with each row corresponding to a study or recall event and tracking for each event a subject index, a trial index, an input or output position, and item id. To identify items, we'll just use the text of the corresponding source unit either studied or recalled. \n",
    "\n",
    "Uniquely with respect to narrative recall data, we're also interested in tracking cues in narratives that connect items semantically. Given our understanding of how the Landscape and CMR models work, we'll focus on tracking:\n",
    "\n",
    "1. Co-occurrence of idea units within the same sentence (characterized as reading \"cycles\" in the documentation of the Landscape model)\n",
    "2. Semantic similarity between idea units as tracked in sentence embeddings corresponding to the Sentence-BERT vector space model of word semantics\n",
    "\n",
    "Cycle identities will be included within our long table representations of the data, but semantic similarity matrices between source units for each story will be tracked separately, retrieved when relevant for analyses based on event details."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e766b8a6",
   "metadata": {},
   "source": [
    "## Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3aa4994",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from IPython.display import Markdown\n",
    "\n",
    "#def render_tex(tex_path, bib_path, csl_path):\n",
    "#    result = !pandoc -C --ascii {tex_path} -f latex -t markdown_mmd --bibliography {bib_path} --csl {csl_path}\n",
    "#    return Markdown('\\n'.join(result))\n",
    "\n",
    "#render_tex('writing/BrownSchmidt_Dataset.tex', 'writing/references.bib', 'writing/main/apa.csl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f983001",
   "metadata": {},
   "source": [
    "Human raters have gotten us most of what we want in the spreadsheet at `data/raw/Narrative Recall Data.xlsx`. Most preprocessing using external data is devoted to identifying otherwise ambiguous relationships between source idea units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad552f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependencies\n",
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# model for computing sentence embeddings\n",
    "embedding_model = SentenceTransformer(\"paraphrase-MiniLM-L12-v2\")\n",
    "\n",
    "# model for detecting reading cycles\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "\n",
    "# key paths\n",
    "source_directory = os.path.join('data', 'raw')\n",
    "text_directory = os.path.join('data', 'texts')\n",
    "target_directory = os.path.join('data', 'sequences', 'human')\n",
    "\n",
    "# names for relevant passages\n",
    "passage_names = ['Fisherman', 'Supermarket', 'Flight', 'Cat', 'Fog', 'Beach']\n",
    "\n",
    "# we use the original xlsx\n",
    "data = pd.read_excel(os.path.join(\n",
    "    source_directory, 'Narrative Recall Data.xlsx'), \n",
    "                     list(range(22)), engine='openpyxl')\n",
    "\n",
    "data[0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd04e71d",
   "metadata": {},
   "source": [
    "## Story Information\n",
    "- Strings identifying idea units within each story\n",
    "- Semantic similarity matrix between source idea units\n",
    "- Cycles grouping source idea units based on co-occurence in the same sentence\n",
    "\n",
    "Later when we process specific trials, we'll retrieve this information to identify study events in our final table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f3c38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cycles = []\n",
    "all_source_units = []\n",
    "all_similarities = []\n",
    "story_sequence = []\n",
    "\n",
    "for trial_index, trial in tqdm(data[0].groupby(['story', 'timeTest'])):\n",
    "    \n",
    "    # we only consider each story once\n",
    "    if trial['timeTest'].values[0] > 1:\n",
    "        continue\n",
    "    \n",
    "    # identify story\n",
    "    story_index = trial['story'].values[0]\n",
    "    story_sequence.append(story_index)\n",
    "    \n",
    "    # source units are reproduced perfectly in xlsx file\n",
    "    source_units = [each for each in list(trial['origText']) if type(each) == str]\n",
    "    \n",
    "    # collect relevant text\n",
    "    with open(os.path.join(\n",
    "        text_directory, passage_names[story_index-1] + '.txt'), encoding='utf8') as f:\n",
    "        story_text = f.read()\n",
    "        \n",
    "    # sort units into cycles based on co-occurence in the same sentence\n",
    "    # build cycle vector assigning a cycle index to each idea unit\n",
    "    cycles = []\n",
    "    cycle_index = 0\n",
    "    last = 0\n",
    "    story_doc = nlp(story_text)\n",
    "    \n",
    "    for unit in source_units:\n",
    "        \n",
    "        # locate the unit in story_text\n",
    "        unit_loc = story_text.index(unit)\n",
    "        \n",
    "        # find the sentence corresponding to its first character\n",
    "        unit_sentence = story_doc.char_span(unit_loc, unit_loc+len(unit.strip())).sent.start\n",
    "        \n",
    "        # if the sentence differs from the last considered one, that's a new cycle\n",
    "        if unit_sentence != last:\n",
    "            cycle_index += 1\n",
    "            last = unit_sentence\n",
    "\n",
    "        cycles.append(cycle_index)\n",
    "                \n",
    "    # track semantic similarity between each source unit\n",
    "    embeddings = embedding_model.encode(source_units)\n",
    "    similarities = util.pytorch_cos_sim(embeddings, embeddings).detach().tolist()\n",
    "    \n",
    "    all_cycles.append(cycles)\n",
    "    all_similarities.append(similarities)\n",
    "    all_source_units.append(source_units)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad7a854",
   "metadata": {},
   "source": [
    "Let's do a sanity check: lengths of cycle, similarity, and source unit vectors should be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41a866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(all_source_units)):\n",
    "    print(len(all_cycles[i]), len(all_similarities[i]), len(all_source_units[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af24fb5",
   "metadata": {},
   "source": [
    "## Trial Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8e9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "# consider each unique trial\n",
    "for subject_index, subject in enumerate(data):\n",
    "    for trial_index, trial in enumerate(\n",
    "        data[subject].groupby(['story', 'timeTest'])):\n",
    "        \n",
    "        # identify story, timeTest (we already have subject_index)\n",
    "        story_index = trial[0][0]-1\n",
    "        timeTest = trial[0][1]\n",
    "        passage_name = passage_names[story_index]\n",
    "        \n",
    "        # build study event list based on extracted story information\n",
    "        for unit_index, unit in enumerate(all_source_units[story_index]):\n",
    "            results.append(\n",
    "                [subject, trial_index, 'study', unit_index+1, \n",
    "                 unit, unit_index, all_cycles[story_index][unit_index], \n",
    "                 story_index, passage_name, timeTest])\n",
    "        \n",
    "        # we only care about the posRec column\n",
    "        # create a recall event wherever a value is stored\n",
    "        for serialPos, posRec in enumerate(list(trial[1]['posRec'])):\n",
    "            \n",
    "            # move to next entry if value can't be cast as integer\n",
    "            try:\n",
    "                posRec = int(posRec)\n",
    "            except ValueError:\n",
    "                continue\n",
    "            \n",
    "            results.append(\n",
    "                [subject, trial_index, 'recall', posRec,\n",
    "                 all_source_units[story_index][serialPos-1], serialPos-1,\n",
    "                 all_cycles[story_index][serialPos-1], \n",
    "                 story_index, passage_name, timeTest])\n",
    "            \n",
    "results = pd.DataFrame(results, columns=[\n",
    "    'subject', 'list', 'trial_type', 'position', 'item', 'item_index', 'cycle', \n",
    "    'story_index', 'story_name', 'time_test'])\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafa1fb5",
   "metadata": {},
   "source": [
    "## Store Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2b5c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# similarities\n",
    "similarity_result = {passage_names[i]: all_similarities[i] \n",
    "                     for i in range(len(all_similarities))}\n",
    "\n",
    "with open('data/similarities.json', 'w') as f:\n",
    "    f.write(json.dumps(similarity_result))\n",
    "    \n",
    "results.to_csv('data/psifr_sbs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
