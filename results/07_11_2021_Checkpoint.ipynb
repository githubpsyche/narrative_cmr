{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82a27dbb-e4ac-46b5-8656-1a16fb6e0f0b",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "# <center> What Comprehension Has to Do With Memory:<br>A First Look at the Landscape Model\n",
    "    \n",
    "<center> <img src=\"https://pbs.twimg.com/media/E4bioegWUAATLwP.jpg\" width=70%> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f25c77b-e757-4101-80d8-7ba3b606ff15",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "Models of semantic organization of free recall that we've explored (e.g., Morton & Polyn, 2016) have more or less supposed that semantic associations between items shaping recall are static across the course of list presentation. But when it comes to recall for narratives, written accounts of connected events/ideas, this assumption is straightforwardly violated. Theories of reading comprehension all but equate the process with the *evolution* of pre-existening semantic associations between story components into an integrated representation of the overall narrative. This basic idea - that alterations of item associations during encoding might not depend entirely on temporal features - defines a frontier for memory research that's gone largely unexplored by retrieved context theorists. \n",
    "\n",
    "To begin that exploration, we here explore what one comprehension model - the revised landscape model (LS-R) - can tell us about free recall that a retrieved context model like CMR cannot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05f48e9-283e-43bb-9ba8-d3ecdced905a",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    },
    "tags": []
   },
   "source": [
    "## Differences and Homologies Between Accounts of Word List and Narrative Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813c2f60-3d71-4c0d-bdcb-45cf2c6f2682",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "Retrieved context models like CMR and comprehension models like LS-R are both largely connectionist. The effect of encoding a new piece of information into memory also proceeds along two similar abstract steps:\n",
    "\n",
    "1. Iterative updates to a slowly-drifting representation of recent experience based on a function of current experience and pre-existing memory associations\n",
    "2. Corresponding updates to a long-term associative memory store based on item coactivations within the shorter-term recency-weighted representation \n",
    "\n",
    "The dynamics updating these dual representations differ, of course, and how they differ depends on the models under consideration. However, some key features of comprehension models that don't come up in retrieved context theory include:\n",
    "\n",
    "### Convergence\n",
    "How strongly a piece of information gets activated depends on support received from related information. In memory, this drives already highly connected idea units in a story toward even greater connectivity by the end of reading, and vice versa for more isolated units. Dynamics like these don't emerge in a model like CMR.\n",
    "\n",
    "### Mapping\n",
    "Concrete linguistic structures in a story can relate idea units without in memory based on properties aside from temporal contiguity or even semantic similarity. Different models characterize this mapping process in different ways or with different degrees of sophistication, but all emphasize the importance of this process.\n",
    "\n",
    "### Coherence-Based Retrieval\n",
    "Comprehension is considered roughly goal-directed, meaning-seeking, aiming at efficient integration of processed ideas into a coherent (logical/consistent) representation. The main consequence of this principle is that readers automatically resolve \"cohesion gaps\" in texts. When processes mapping between incoming and previously activated concepts fail, readers tend to nonetheless infer relations between text constituents automatically, inferring relationships based on prior knowledge to realize a fulyl connected narrative representation.\n",
    "\n",
    "### Levels of comprehension\n",
    "Some models distinguish between surface, text-base, and situation model levels of text understanding. Differences in processes for resolving coherent representations of a text at each level, mediated by reader goals and abilities, are thought to differentially influence final associations between idea units during recall. Other models avoid enforcing these distinctions, but tend to either be very flexible (effectively leaving the implications of these differences to be weighed on a case by case basis through parameter configuration) or very simple. The landscape model is like this!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba79995-7da1-4d29-84a9-d31d8fb41f41",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "## Where the Landscape Model Stands Among Other Models\n",
    "We can think of comprehension models as *mainly* differing about two issues. \n",
    "\n",
    "### How Do Narratives Connect Ideas?\n",
    "The first issue concerns the narrative features that tend to relate idea units together in memory. For example, the construction-integration model emphasizes argument overlap between units, while the causal networking model emphasizes cause-effect relations within a story. Other models like the structure-building and event-indexing model associate idea units into discrete groups based on transitions within a story as by scene, time, or perspective. \n",
    "\n",
    "The landscape model of reading comprehension is sort of agnostic about these matters. Researchers are provided broad latitude to specify how units are grouped into \"cycle\" entities that enforce unit coactivation during model simulation.\n",
    "\n",
    "### Predictive and Bridging Inference\n",
    "Different models specify different accounts of how readers 1) anticipate information yet to be revealed explicitly in the text (predictive inference) and 2) infer mediating information that specifies the conceptual relations between textual ideas (bridging inference). In general, models center an interaction between pre-existing semantic and ongoing text-specific knowledge  in accounts of these processes, but the details of these theories can result in very distinct predictions about the kinds of associations drawn between ideas.\n",
    "\n",
    "While these inference-based associations are pertinent for free recall research as potential sources of response organization, comprehension researchers relate them to a broad variety of other phenomena, including reading times and the content and speed of answers to rich questions about story content and meaning. The breadth of phenomena these models try to account for presents rich opportunities for model convergence across research paradigms. Our analyses of response organization broaden this repertoire further!\n",
    "\n",
    "The landscape model posits a spreading activation process to account for predictive processes during reading. When you process an idea unit in a story, its node within a idea network gets activated. Some of this activation is then passed to other idea units according to the strengths of its connections to them and modulated by a decay rate. Connection strengths themselves are initialized based on pre-experimental semantic similarity, but can change over the course of model simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9112a10-5601-4954-85a2-4c77d884d3d1",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "### The Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33449711-435d-47e9-883a-7ec87bbb1c91",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "To encode a text into the landscape model (LS-R), it is initially segmented into text units (e.g., words or propositions) and reading cycles (e.g., clauses or sentences) depending on researcher preference. These cycles are processed sequentially to simulate reading.  \n",
    "\n",
    "The landscape model is more or less a spreading activation model of reading comprehension. Each relevant idea unit has an activation level (initialized at 0) and a configuration of connections to all other idea units. These connections are initialized based on cosine similarities of word vectors. For my work, I've been using a vector space based on the language model BERT called SentenceBERT.\n",
    "\n",
    "As each reading cycle is simulated, unit activations are updated according to the following four mechanisms:\n",
    "1. **Attention**. Units of the current cycle are activated to the highest allowed value.\n",
    "2. **Recency**. Units from prior cycles carry residual activation following a decay rule.\n",
    "3. **Spreading activation**. Text units receive activation via connections with text units activated in the current cycle according to a hyperbolic tangent function that effectively imposes a ceiling on the result:\n",
    "\n",
    "<center> <img src=\"../img/Hyperbolic_Tangent.svg.png\" width=50%> </center>\n",
    "\n",
    "The math of this goes like:\n",
    "\n",
    "$$\n",
    "{A}_{i_c}={\\displaystyle \\sum_{j=1}^m\\delta \\cdot {A}_{j_{c-1}}\\cdot \\sigma \\left({S}_{i{j}_{c-1}}\\right)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sigma (x)=Tanh\\left[3\\left(X-1\\right)\\right]+1\n",
    "$$\n",
    "\n",
    "where $A$, $S$, $i$, and $c$ denote activation, connection strengths, the current unit, and the current cycle, respectively, while the parameter $\\delta$ enforces a decay rate of unit activation, and $\\sigma$ enforces a positive logarithmic change in the connection strength. \n",
    "\n",
    "4. **Memory capacity**. Also, a parameter sets a limit on the total amount of activation allowable within any reading cycle. Activations are reduced proportionately to attain the limit whenever it would otherwise be exceeded."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f551c5b7-afff-49ac-9af9-706cc3232707",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "Model connection weights are then updated based on the unit coactivity according to a fairly traditional Hebbian process:\n",
    "\n",
    "$$\n",
    "{S}_{i{j}_c}={S}_{i{j}_{c-1}}+\\lambda \\cdot {A}_{i_c}\\cdot {A}_{j_c}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d35a1-6a92-44b4-8e89-6b81fdf3056c",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "I draft an initial diagram of the process here:\n",
    "\n",
    "<center> <img src=\"../img/landscape_model.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e2a2e-554c-4e19-9dba-78ee5dc85116",
   "metadata": {},
   "source": [
    "## How Does the Landscape Model Relate to CMR?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f14c6-c33b-4443-b6e1-fa74e71616eb",
   "metadata": {},
   "source": [
    "There are striking similarities between the two models. The Landscape model's activation vector changes a lot like CMR's context vector. When an item (idea unit) is processed, pre-existing associations are retrieved and integrated into the vector. A decay mechanism ensures that past experiences have dwindling representation in the activation vector based on recency. Extra mechanisms ensure that the activations corresponding to any one item never exceed pre-defined thresholds. And then coactivation within this vector are used to updated a long-term associative memory store, modulated by some learning rate parameter! The math of how this happens are distinct, but the correspondences are uncanny at a high level.\n",
    "\n",
    "But then again there are substantial differences between the two models that each might negotiate to account for a broader collection of phenomena. I think the core differences that give the landscape model an advantage over CMR can be narrowed down to two features:\n",
    "\n",
    "### Unit co-processing within a cycle\n",
    "In the landscape model, ideas can be processed *together* - like when they occur within the same sentence or other structure. This difference might seem like an afterthought at first, but since learning is driven by unit coactivation, it has important consequences for later recall. Recency mechanisms in CMR ensure that items processed near one another are more strongly associated in memory, but the extent of this association depends on the value of the drift/decay rate parameter enforcing recency-weighting in the context vector. \n",
    "\n",
    "The cycle construct disentangles co-processing from drift rate and (with activation normalization) focuses association strengthening to units with connections to _all_ units in the current cycle. \n",
    "\n",
    "### Dynamic semantic, not just temporal, associations\n",
    "During encoding, only pre-existing serial positional associations are retrieved during computation of contextual input. The state of context at any given simulation step is mainly a function of these retrieved temporal associations and decayed memories of similar retrievals from past simulation steps. \n",
    "\n",
    "In the landscape model, retrieved associative information is at least initially semantic - literally the semantic textual similarities computed between each unit before simulation started.  The state of context at any given simulation step is mainly a function of these retrieved *semantic* associations and decayed memories of similar retrievals from past simulation steps. \n",
    "\n",
    "The result is that at any given learning step, the extent to which any connection weights between units are updated is strongly modulated by pre-experimental semantic similarity to an extent that doesn't happen in CMR. If CMR could initialize with semantic similarities in the way the Landscape Model does by default, it would have this feature.\n",
    "\n",
    "### Leveraged to account for convergent and inferential dynamics\n",
    "Coactivation in general (whether within or outside a cycle) is central to how the landscape model is able to account for complex features of comprehension. Within the model, two distinct ideas activated together in turn drives especial activation for ideas that are strongly associated with them both simultaneously, even if they haven't actually been processed yet. Dynamics like these are how the model is applied to account for the way inferential processes shape outcome variables like reading or response times.\n",
    "\n",
    "If CMR could figure semantic information into its account of how internal contextual representations dynamically fluctuate over the course of list study, then it probably could similarly account for these unique aspects of story comprehension while at the same preserving a capacity to account for factors organizing free recall of word lists with more subtle semantic associations.\n",
    "\n",
    "<center> <img src=\"https://pbs.twimg.com/media/E4bioegWUAATLwP.jpg\" width=50%> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e6922e-bd31-4774-b9ee-8eaa154f59fe",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "## Current Analyses\n",
    "Previous work focused on predicting inference activation (Yeari and van den Broek, 2015) found that integrating LSA computations within a dynamic comprehension model resulted in better predictions than using LSA alone. We'll similarly explore whether connections found through simulation of the landscape model better account for recall rates and response organization in free recall of narratives than semantic similarities alone.\n",
    "\n",
    "If relevant, we'll also try to rule out a plausible potential explanation for our results: that, like CMR, the landscape model also primarily encodes information about serial order into idea units' connection weights. If it turns out that LS-R indeed works this way, then a more proper focus of this project might be to characterize CMR's capacity to account for benchmark phenomena in the reading comprehension modeling literature. Otherwise, further work will focus on integrating the Landscape model's affordances into retrieved context theory. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0717b1c2-ba3c-4aad-96ad-4775c3192ad2",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "activeView": "grid_default",
      "views": {
       "grid_default": {
        "col": null,
        "height": 2,
        "hidden": true,
        "row": null,
        "width": 2
       }
      }
     }
    }
   },
   "source": [
    "### Data\n",
    "<center> <img src=\"../img/cutler_method.png\" width=50%> </center>\n",
    "\n",
    "Recall for narratives, if split into idea units -- \"meaningful chunks of information that convey a piece of the narrative\" -- that are numbered according to chronological order, can be examined using analytic techniques developed for free and serial list recall tasks. This framework enables direct comparison between ideas, assumptions, and models applied to understand how people remember sequences such as word lists and those used to understand memory for narrative texts. To support analysis of narrative recall this way, we considered a dataset collected, preprocessed, and presented by Cutler, Palan, Polyn, and Brown-Schmidt (2019). In corresponding experiments, 22 research participants read 6 distinct short stories. Upon reading a story, participants performed immediate free recall of the narrative twice. Three weeks later, participants performed free recall of each narrative again. Each recall period was limited to five minutes. Following data collection, a pair of research assistants in the Brown-Schmidt laboratory were each instructed to independently split stories and participant responses into idea units as defined above, and to identify correspondences between idea units in participant responses and corresponding studied stories reflecting recall. Following this initial preprocessing, research assistants then compared and discussed their results and recorded consensus decisions regarding the segmentation and correspondence of idea units across the dataset. Further analysis focused on the sequences of story idea units recalled by participants on each trial as tracked by these researchers. Where relevant (e.g. for grouping idea units into cycles), the spaCy library for advanced natural language processing is applied to automatically segment passages into unique sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e20f32-ed2f-4713-ad0e-069b54856dc0",
   "metadata": {},
   "source": [
    "### Semantic Textual Similarity\n",
    "To compute pre-experimental semantic textual similarity between extracted idea units, we lean on the SentenceTransformers library, a Python framework for state-of-the-art sentence, text and image embeddings. The most advanced models supported by the library apply siamese and triplet network structures to fine-tune the BERT language model to achieve state-of-the-art performance on sentence-pair regression tasks including semantic textual similarity (Reimers & Gurevych, 2019). To compute the semantic similarity between two idea units, a vector representation corresponding to each word within the idea units are retrieved from the pretrained paraphrase-mpnet-base-v2 model, selected for its state of the art performance across various benchmarks. To obtain a vector representation for each entire idea unit, a mean vector is computed over every word in the unit. Finally, the cosine similarity of these mean-pooled idea vectors is used to represent the semantic textual similarity between the idea units under consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccdeffd-fd69-401b-ae77-b10691c59436",
   "metadata": {},
   "source": [
    "### Semantic and Temporal Organization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f84b79-6789-4ad8-9f37-008db8fd5436",
   "metadata": {},
   "source": [
    "## Baseline Overview\n",
    "Before digging into the landscape model, we open with some baseline temporal and semantic organizational analyses to help build an initial grasp of dataset characteristics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c328b52-c7bb-40d5-abe0-9ff9645b0018",
   "metadata": {},
   "source": [
    "### Recall Rate by Time of Test\n",
    "<center> <img src=\"../results/Catplot_Probability_Recall_by_Time_Test.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f319769-4826-4178-885c-1f922c58abe2",
   "metadata": {},
   "source": [
    "### Recall Rate by Serial Position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29e6041-2798-4b39-af60-87ba9b693962",
   "metadata": {},
   "source": [
    "<center> <img src=\"../results/Lineplot_SPC_by_Story_Time_Test_1.svg\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df49fa5-f0bd-4933-bfa5-d45a949fcc32",
   "metadata": {},
   "source": [
    "<center> <img src=\"../results/Lineplot_SPC_by_Story_Time_Test_2.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8036d29-c9b2-40b4-a089-8bd69de915f1",
   "metadata": {},
   "source": [
    "<center> <img src=\"../results/Lineplot_SPC_by_Story_Time_Test_3.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16f02b9-ac8f-47b6-ae44-b2b1dc8ff819",
   "metadata": {},
   "source": [
    "### Recall Rate by Semantic Centrality\n",
    "<center> <img src=\"../results/Lmplot_Probability_Recall_by_Mean_MiniLM_L12_v2_Cosine_Similarity.svg\"> </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a30c7a-a8b9-4bc4-9bca-9b735670434d",
   "metadata": {},
   "source": [
    "### Lag-CRP\n",
    "<center> <img src=\"../results/Lineplot_CRP_by_Time_Test.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fab6c5-cb71-4996-920d-b0365bc356de",
   "metadata": {},
   "source": [
    "### Semantic CRP\n",
    "<center> <img src=\"../results/Lineplot_SemanticCRP_by_Time_Test.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f87c0d-dc4e-4373-8d5d-1c2490e4f02c",
   "metadata": {},
   "source": [
    "### Semantic Lag-Rank Organizational Score by Time_Test and Subject\n",
    "<center> <img src=\"../results/Lmplot_Time_Test_by_Distance_Rank_Glove840B_by_Subject.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8b0e4-aa9c-42d0-a357-d7f078a6ec5e",
   "metadata": {},
   "source": [
    "## Simulation Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018a4858-39b1-4c61-8786-365e08b21f68",
   "metadata": {},
   "source": [
    "### Recall Clustering by Model Connection Weights by Simulation Step\n",
    "Time_Test == 2\n",
    "\n",
    "<center> <img src=\"../results/Lineplot_LMR_Distance_Rank_by_Simulation_Step_by_Story.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f98056e-2244-4520-81bf-5b1147f610d1",
   "metadata": {},
   "source": [
    "### Recall Rate by Mean Simulated Connection Weight\n",
    "<center> <img src=\"../results/Lmplot_Probability_Recall_by_Mean_Connection_Weight.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06fd82b-93f1-44ee-991f-1c2754d9ca8f",
   "metadata": {},
   "source": [
    "### Recall Rate by Mean Simulated Connection Weight by Story\n",
    "<center> <img src=\"../results/Lmplot_Probability_Recall_by_Mean_Connection_Weight_by_Story.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ae53a9-fd88-4dfe-8b11-9008498c5696",
   "metadata": {},
   "source": [
    "### Model DistanceCRP by Time_Test\n",
    "<center> <img src=\"../results/Lineplot_Model_DistanceCRP_by_Time_Test.svg\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1825b89-efab-4af5-99ab-d5f6c81e922b",
   "metadata": {},
   "source": [
    "### Correlations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6d9798-e941-449d-b98e-dd42da638588",
   "metadata": {},
   "source": [
    "\n",
    "for time_test in range(1, 4):...\n",
    "\n",
    "Time Test == 1\n",
    "\n",
    "|                   |   time_test |      input |     recall |   cosine_similarity |\n",
    "|:------------------|------------:|-----------:|-----------:|--------------------:|\n",
    "| time_test         |         nan | nan        | nan        |          nan        |\n",
    "| input             |         nan |   1        |  -0.404539 |           -0.291262 |\n",
    "| recall            |         nan |  -0.404539 |   1        |            0.141831 |\n",
    "| cosine_similarity |         nan |  -0.291262 |   0.141831 |            1        |\n",
    "\n",
    "Time Test == 2\n",
    "\n",
    "|                   |   time_test |      input |      recall |   cosine_similarity |\n",
    "|:------------------|------------:|-----------:|------------:|--------------------:|\n",
    "| time_test         |         nan | nan        | nan         |         nan         |\n",
    "| input             |         nan |   1        |  -0.565403  |          -0.291262  |\n",
    "| recall            |         nan |  -0.565403 |   1         |           0.0794009 |\n",
    "| cosine_similarity |         nan |  -0.291262 |   0.0794009 |           1         |\n",
    "\n",
    "Time Test == 3\n",
    "\n",
    "|                   |   time_test |      input |      recall |   cosine_similarity |\n",
    "|:------------------|------------:|-----------:|------------:|--------------------:|\n",
    "| time_test         |         nan | nan        | nan         |         nan         |\n",
    "| input             |         nan |   1        |  -0.194043  |          -0.291262  |\n",
    "| recall            |         nan |  -0.194043 |   1         |           0.0938463 |\n",
    "| cosine_similarity |         nan |  -0.291262 |   0.0938463 |           1         |"
   ]
  },
  {
   "cell_type": "raw",
   "id": "297ddbed-7e75-4fca-a50b-960b9001271d",
   "metadata": {},
   "source": [
    "all 1\n",
    "(0.20498548566393227, 0.0018626171269409497)\n",
    "Beach 1\n",
    "(0.28822791528881875, 0.07129391548741018)\n",
    "Cat 1\n",
    "(-0.06011088824931351, 0.7162255822573234)\n",
    "Fisherman 1\n",
    "(-0.10400286615456383, 0.5175625420335415)\n",
    "Flight 1\n",
    "(0.0553178477899796, 0.7245950163885214)\n",
    "Fog 1\n",
    "(-0.046762861578853676, 0.8205469604144963)\n",
    "Supermarket 1\n",
    "(0.2524346179227378, 0.12104727261478568)\n",
    "\n",
    "all 2\n",
    "(0.13876745650864553, 0.03626288077973961)\n",
    "Beach 2\n",
    "(0.19483613479977013, 0.2282943390529712)\n",
    "Cat 2\n",
    "(-0.1832297092269139, 0.2641975879195285)\n",
    "Fisherman 2\n",
    "(-0.16068826311412676, 0.3155576325390513)\n",
    "Flight 2\n",
    "(0.018965344899692503, 0.9039205867625443)\n",
    "Fog 2\n",
    "(-0.016675342911965013, 0.9355600481391892)\n",
    "Supermarket 2\n",
    "(0.16734159930802656, 0.30855935945026114)\n",
    "\n",
    "all 3\n",
    "(0.13116966064987176, 0.047896239035553526)\n",
    "Beach 3\n",
    "(-0.002054379314918106, 0.9899620593194013)\n",
    "Cat 3\n",
    "(-0.13565199456859686, 0.41028043031611516)\n",
    "Fisherman 3\n",
    "(0.025822648044829016, 0.8726771733565061)\n",
    "Flight 3\n",
    "(0.059009305086631825, 0.7070095018260095)\n",
    "Fog 3\n",
    "(-0.18522766191271453, 0.3649871323188733)\n",
    "Supermarket 3\n",
    "(0.321026951635996, 0.0462967024795843)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4accc1-f80e-419f-b002-dc20c0777f41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 2,
      "defaultCellHeight": 60,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
